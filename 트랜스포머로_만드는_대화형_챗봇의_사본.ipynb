{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mackenziepark/Manhattan-Distance-testing/blob/main/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%EB%A1%9C_%EB%A7%8C%EB%93%9C%EB%8A%94_%EB%8C%80%ED%99%94%ED%98%95_%EC%B1%97%EB%B4%87%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA5npCtDxLqS",
        "outputId": "160bea47-67ec-499c-8382-4ad45b4170a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bEjFAB_Vfyv"
      },
      "source": [
        "트랜스포머로 만드는 대화형 챗봇"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ty3bEihVmnz"
      },
      "source": [
        "Step 1. 데이터 수집하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge2Td1rYVqXa"
      },
      "source": [
        "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용\n",
        "\n",
        "사용 데이터: songys/Chatbot_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDahry7fVuE5"
      },
      "source": [
        "일상다반서 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링\n",
        "\n",
        "데이터 shape 및 결측치 확인하였음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo3v4ymKRLln",
        "outputId": "11dcf989-1c09-4745-b46b-cf91a05d4249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                         Q                   A  label\n",
            "0                   12시 땡!          하루가 또 가네요.      0\n",
            "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
            "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
            "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
            "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
            "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
            "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
            "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
            "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
            "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import os\n",
        "data_path = \"/content/drive/MyDrive/test/ChatbotData.csv\"\n",
        "if os.path.exists(data_path):\n",
        "    data = pd.read_csv(data_path, encoding='utf-8')\n",
        "    print(data.head(10))\n",
        "else:\n",
        "    print(f\"File not found at {data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "구글 코랩(Google Colab)에서 구글 드라이브(Google Drive)를 마운트하고, https://github.com/songys/Chatbot_data를 저장한 ChatbotData.csv 파일을 불러와서 데이터를 출력한다.\n",
        "\n",
        "(1)from google.colab import drive:\n",
        "구글 코랩에서 구글 드라이브를 마운트하기 위해 필요한 라이브러리를 임포트한다.\n",
        "\n",
        "(2)drive.mount('/content/drive'):\n",
        "구글 드라이브를 /content/drive 경로에 마운트한다.\n",
        "\n",
        " (3)import pandas as pd:\n",
        "데이터 분석을 위해 판다스(Pandas) 라이브러리를 임포트한다.\n",
        "\n",
        "(4) import os:\n",
        "운영체제와의 상호작용을 위해 os 모듈을 임포트한다.\n",
        "\n",
        "(5)data_path = \"/content/drive/MyDrive/test/ChatbotData.csv\":\n",
        "불러올 CSV 파일의 경로를 변수 data_path에 저장한다.\n",
        "\n",
        "(6) if os.path.exists(data_path)::\n",
        "해당 경로에 파일이 존재하는지 확인한다. 존재하면 다음 코드를 실행하고, 존재하지 않으면 else 블록을 실행한다.\n",
        "\n",
        "\n",
        "(7) data = pd.read_csv(data_path, encoding='utf-8'):\n",
        "지정된 경로에서 CSV 파일을 UTF-8 인코딩으로 읽어와서 판다스 데이터프레임으로 저장한다.\n",
        "\n",
        "(8)print(data.head(10)):\n",
        "읽어온 데이터의 첫 10행을 출력한다."
      ],
      "metadata": {
        "id": "DNtxSXD5rhgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Q_J2xPxfq_",
        "outputId": "d97bb228-27d1-4136-c1bd-b45ddb901a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                         Q                   A  label\n",
            "0                   12시 땡!          하루가 또 가네요.      0\n",
            "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
            "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
            "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
            "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
            "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
            "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
            "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
            "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
            "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0\n",
            "          Q     A\n",
            "label            \n",
            "0      5290  5290\n",
            "1      3570  3570\n",
            "2      2963  2963\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/MyDrive/test/ChatbotData.csv\"\n",
        "if os.path.exists(data_path):\n",
        "    data = pd.read_csv(data_path, encoding='utf-8')\n",
        "    print(data.head(10))\n",
        "    grouped_data = data.groupby(['label']).count()\n",
        "    print(grouped_data)\n",
        "else:\n",
        "    print(f\"File not found at {data_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IKQdNhpo1Qvj",
        "outputId": "57673216-55ab-4a24-e1b6-906ba78902d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a38baeb2-a609-43b8-a2da-c2f00459b167\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a38baeb2-a609-43b8-a2da-c2f00459b167')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a38baeb2-a609-43b8-a2da-c2f00459b167 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a38baeb2-a609-43b8-a2da-c2f00459b167');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7955067c-60be-40d3-87c6-c0fb093a4324\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7955067c-60be-40d3-87c6-c0fb093a4324')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7955067c-60be-40d3-87c6-c0fb093a4324 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 Q            A\n",
              "0           12시 땡!   하루가 또 가네요.\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
              "4          PPL 심하네   눈살이 찌푸려지죠."
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = data[['Q', 'A']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j97JxPrY1c_j",
        "outputId": "83ae0495-5c2d-4a93-e894-95fbe160dc33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11823, 2)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RMMrKxn6UNH",
        "outputId": "a2a6d144-cad5-496e-f21d-5720b3d2a800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Q    0\n",
              "A    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5io5TL7V01d"
      },
      "source": [
        "Step 2. 데이터 전처리하기\n",
        "preprocess_sentence:\n",
        "\n",
        "정규 표현식(Regular Expression) 을 사용하여 구두점(punctuation) 을 제거\n",
        "토크나이징(tokenizing) 하는 일에 방해가 되지 않도록 정제\n",
        "불용어 제거: 한국어 불용어 리스트를 활용하였습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdh9mS757keO",
        "outputId": "53e5cf1b-2900-409c-c3ea-a825c01e8723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) questions 리스트와 answers 리스트의 길이를 출력하여 전체 샘플 수를 확인한다.\n",
        "\n",
        "(2) 전처리된 질문과 답변의 샘플을 출력한다.\n",
        "\n",
        "(3) 인덱스가 1인 요소(즉, 두 번째 요소)를 출력한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "WWFZxDZQvcKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zFnVlrN-eMC",
        "outputId": "5e99e22d-3513-4b70-d3ac-6e3f5a9d57d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "False\n",
            "['ChatbotData.csv', '한국어불용어단어.gdoc']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "stopwords_path = \"/content/drive/MyDrive/test/한국어불용어단어.txt\"\n",
        "print(os.path.exists(stopwords_path))\n",
        "print(os.listdir('/content/drive/MyDrive/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc8mP8_r_A9P"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # (a-z, A-Z, ㄱ-ㅎ, ㅏ-ㅣ, 가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
        "  sentence = re.sub(r\"[^a-zA-Zㄱ-ㅣ가-힣0-9?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "# 불용어 제거\n",
        "  sentence_list = []\n",
        "  for s in sentence.split(' '):\n",
        "    if s not in stopwords:\n",
        "      sentence_list.append(s)\n",
        "\n",
        "  sentence = \" \".join([str(ele) for ele in sentence_list])\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFBLrBup_Fcn"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljPFWdDO_IFw"
      },
      "outputs": [],
      "source": [
        "questions = []\n",
        "answers = []\n",
        "for sentence in data['Q']:\n",
        "  questions.append(preprocess_sentence(sentence))\n",
        "\n",
        "for sentence in data['A']:\n",
        "  answers.append(preprocess_sentence(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEEhh26-_MC4",
        "outputId": "d8eb6792-e5d4-4b79-8225-830aa227939a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플 수 : 11823\n",
            "전체 샘플 수 : 11823\n"
          ]
        }
      ],
      "source": [
        "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
        "print('전체 샘플 수 :', len(questions))\n",
        "print('전체 샘플 수 :', len(answers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-bGUEgL_P2B",
        "outputId": "156e2527-4f85-4dbe-b029-c5cacf88c4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전처리 후의 22번째 질문 샘플: 1지망 학교 떨어졌어\n",
            "전처리 후의 22번째 답변 샘플: 위로해 드립니다 .\n"
          ]
        }
      ],
      "source": [
        "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[1]))\n",
        "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPXO5fNHWAn9"
      },
      "source": [
        "Step 3. SubwordTextEncoder 사용하기\n",
        "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다.\n",
        "하지만 해당 프로젝트에서는 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oet_9Cf-_g2H"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46uDIMVu_qt2"
      },
      "outputs": [],
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. START_TOKEN은 시작 토큰으로, 어휘 사전의 크기와 같은 고유한 정수를 리스트로 갖는다.\n",
        "\n",
        "2. [tokenizer.vocab_size]는 어휘 사전의 크기를 시작 토큰의 정수로 사용한다.\n",
        "\n",
        "3. END_TOKEN은 종료 토큰으로, 어휘 사전의 크기보다 1 큰 고유한 정수를 리스트로 갖는다.\n",
        "\n",
        "4.[tokenizer.vocab_size + 1]는 어휘 사전의 크기보다 1 큰 값을 종료 토큰의 정수로 사용한다.\n",
        "\n",
        "\n",
        "이렇게 하면 시작 토큰과 종료 토큰은 어휘 사전의 다른 단어들과 겹치지 않는 고유한 정수로 정의되어, 모델이 문장의 시작과 끝을 인식할 수 있게 된다.\n"
      ],
      "metadata": {
        "id": "t0juaPM8x9KV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAt3fgMs_trX",
        "outputId": "5962494c-6d00-47db-cf8b-fffdbde48186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START_TOKEN의 번호 : [8173]\n",
            "END_TOKEN의 번호 : [8174]\n"
          ]
        }
      ],
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po341kbZ_wub",
        "outputId": "2b77a160-77e6-495a-ef38-3c84c4bef9ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8175\n"
          ]
        }
      ],
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq2EdL4c_0bG",
        "outputId": "bd7a324a-5b66-429f-d925-8b4013b0b2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [5764, 610, 2492, 4164]\n",
            "정수 인코딩 후의 21번째 답변 샘플: [2356, 7513, 7, 6276, 97, 1]\n"
          ]
        }
      ],
      "source": [
        "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUlyKkBH_3XQ",
        "outputId": "d5b0d8c3-665b-474d-9bac-ea152e2eaab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 15\n",
        "print(MAX_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WtslIOc_6a2"
      },
      "outputs": [],
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 최대 길이로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNNPdofc__ZB",
        "outputId": "60a61710-bcfe-473c-f4a8-685de63d79ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어장의 크기 : 8175\n",
            "필터링 후의 질문 샘플 개수: 11568\n",
            "필터링 후의 답변 샘플 개수: 11568\n"
          ]
        }
      ],
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aNPXPXBWHxN"
      },
      "source": [
        "1-2. 교사강요(Teacher Forcing) 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7igle9sgAG7F"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 진행한다.\n",
        "\n",
        "1. dataset.batch(BATCH_SIZE)는 데이터셋을 배치 크기만큼 묶는다. 여기서는 64개의 샘플이 한 배치가 된다.\n",
        "\n",
        "2. dataset.prefetch(tf.data.experimental.AUTOTUNE)는 모델이 데이터를 읽어오면서 다음 데이터를 미리 로드할 수 있도록 한다.  \n",
        "\n",
        "3. AUTOTUNE은 텐서플로우가 최적의 프리페치 수를 자동으로 결정하게 한다.\n",
        "\n",
        "결과적으로, 이 코드는 데이터셋을 배치 단위로 전처리하고 최적의 학습 속도를 위해 캐시, 셔플, *프리페치* 작업을 수행한다.\n",
        "\n",
        "(*사용자가 가까운 미래에 탐색할 가능성이 '있는' 페이지에 대해 백그라운드에서 리소스를 추론적으로 가져오는 방식*)\n",
        "\n",
        "\n",
        "Q. 교사 강요(Teacher Forcing) 를 사용하지 않았을 경우, 훈련 과정에서 훈련 속도가 지나치게 느려지는 경우가 있다고 합니다. 그 이유는 무엇인가요?\n",
        "\n",
        "A. 교사 강요를 하지 않은 경우, 잘못된 예측이 다음 시점(time step)의 입력으로 들어가면서 연쇄적으로 예측 정확도에 영향을 미친다.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kc5oKH-nyuoX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICH4jRr0WUhF"
      },
      "source": [
        "Step 4. 모델 구성하기\n",
        "포지셔널 인코딩 레이어\n",
        "\n",
        "스케일드 닷 프로덕트 어텐션\n",
        "\n",
        "멀티 헤드 어텐션\n",
        "\n",
        "패딩 마스크\n",
        "\n",
        "룩 어헤드 마스킹\n",
        "\n",
        "인코더 층 & 인코더\n",
        "\n",
        "디코더 층 & 디코더\n",
        "\n",
        "트랜스포머\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G808YVQwASj4"
      },
      "outputs": [],
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0])\n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "\n",
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output\n",
        "\n",
        "\n",
        "# 멀티 헤드 어텐션 클래스\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# 패딩 마스킹구현 함수\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "\n",
        "# 룩 어헤드 마스킹\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어 제거를 반복하며 데이터의 Q 필드 발화에 대한 A 필드 발화를 추출한다."
      ],
      "metadata": {
        "id": "mieKNZOWy-Y9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGgYz5YAa4M"
      },
      "outputs": [],
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "\n",
        "# 인코더 층을 쌓아 인코더 만들기\n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7whc8JGAfza"
      },
      "outputs": [],
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "\n",
        "\n",
        "# 디코더\n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr9ow4tNAm00"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZStGS1WdAp3Y",
        "outputId": "b3afc784-8566-4254-9cca-5ebed1503f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " encoder (Functional)        (None, None, 256)            3147008   ['inputs[0][0]',              \n",
            "                                                                     'enc_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)    (None, 1, None, None)        0         ['dec_inputs[0][0]']          \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, None, 256)            3674368   ['dec_inputs[0][0]',          \n",
            "                                                                     'encoder[0][0]',             \n",
            "                                                                     'look_ahead_mask[0][0]',     \n",
            "                                                                     'dec_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " outputs (Dense)             (None, None, 8175)           2100975   ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8922351 (34.04 MB)\n",
            "Trainable params: 8922351 (34.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7M6jzHMAuY7",
        "outputId": "f23f3d3e-d9a2-4808-d829-f1e3d44e7e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " encoder (Functional)        (None, None, 256)            3147008   ['inputs[0][0]',              \n",
            "                                                                     'enc_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)    (None, 1, None, None)        0         ['dec_inputs[0][0]']          \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, None, 256)            3674368   ['dec_inputs[0][0]',          \n",
            "                                                                     'encoder[0][0]',             \n",
            "                                                                     'look_ahead_mask[0][0]',     \n",
            "                                                                     'dec_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " outputs (Dense)             (None, None, 8175)           2100975   ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8922351 (34.04 MB)\n",
            "Trainable params: 8922351 (34.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model2 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btY2kYNyAxWh",
        "outputId": "adf9960d-4072-482c-91bd-083106680641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " encoder (Functional)        (None, None, 256)            3147008   ['inputs[0][0]',              \n",
            "                                                                     'enc_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)    (None, 1, None, None)        0         ['dec_inputs[0][0]']          \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, None, 256)            3674368   ['dec_inputs[0][0]',          \n",
            "                                                                     'encoder[0][0]',             \n",
            "                                                                     'look_ahead_mask[0][0]',     \n",
            "                                                                     'dec_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " outputs (Dense)             (None, None, 8175)           2100975   ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8922351 (34.04 MB)\n",
            "Trainable params: 8922351 (34.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model3 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOro_k6rA0p_",
        "outputId": "1366b625-0b29-49b2-9221-9e896923d4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " encoder (Functional)        (None, None, 256)            3147008   ['inputs[0][0]',              \n",
            "                                                                     'enc_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)    (None, 1, None, None)        0         ['dec_inputs[0][0]']          \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, None, 256)            3674368   ['dec_inputs[0][0]',          \n",
            "                                                                     'encoder[0][0]',             \n",
            "                                                                     'look_ahead_mask[0][0]',     \n",
            "                                                                     'dec_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " outputs (Dense)             (None, None, 8175)           2100975   ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8922351 (34.04 MB)\n",
            "Trainable params: 8922351 (34.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model4 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01v7eJlCA4b3",
        "outputId": "592f9ae8-fa6d-4b87-8ead-ba91a77948e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " encoder (Functional)        (None, None, 512)            1365350   ['inputs[0][0]',              \n",
            "                                                          4          'enc_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)    (None, 1, None, None)        0         ['dec_inputs[0][0]']          \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)   (None, 1, 1, None)           0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, None, 512)            1996339   ['dec_inputs[0][0]',          \n",
            "                                                          2          'encoder[0][0]',             \n",
            "                                                                     'look_ahead_mask[0][0]',     \n",
            "                                                                     'dec_padding_mask[0][0]']    \n",
            "                                                                                                  \n",
            " outputs (Dense)             (None, None, 8175)           4193775   ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 37810671 (144.24 MB)\n",
            "Trainable params: 37810671 (144.24 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model6 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEUEziNFA8Jn"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DKnnO-PWcjQ"
      },
      "source": [
        "학습률(Learning rate) 커스텀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOfqsXIHA-9P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGXaCZZ1BECe"
      },
      "outputs": [],
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "9zuPzasWBHBS",
        "outputId": "68cf253c-b926-458c-a029-e76379786cf2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 학습률 스케줄 클래스 정의\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # 여기서 step을 명시적으로 float32로 변환\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'d_model': self.d_model, 'warmup_steps': self.warmup_steps}\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "D_MODEL = 128\n",
        "input_vocab_size = 8000\n",
        "target_vocab_size = 8000\n",
        "MAX_LENGTH = 8000\n",
        "\n",
        "# 학습률 스케줄 및 옵티마이저 설정\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# 정확도 함수 정의\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1,))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n",
        "\n",
        "# 데이터셋과 학습 설정\n",
        "EPOCHS = 50  # EPOCHS 값을 50으로 증가시킴\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 예시 데이터셋 정의\n",
        "# train_inputs와 train_targets는 실제 데이터로 대체해야 합니다.\n",
        "train_inputs = tf.random.uniform((1000, input_vocab_size))\n",
        "train_targets = tf.random.uniform((1000, 1), maxval=target_vocab_size, dtype=tf.int32)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_targets)).batch(BATCH_SIZE)\n",
        "\n",
        "# 모델 학습\n",
        "history1 = model.fit(dataset, epochs=EPOCHS, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzZmcnQA5k2",
        "outputId": "43889f97-67d6-41ec-e80f-1baac60ad41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 24ms/step - loss: 9.1672 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.8259 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.2003 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 7.5078 - accuracy: 0.0020\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.9580 - accuracy: 0.0060\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.5376 - accuracy: 0.0100\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.1516 - accuracy: 0.0270\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.7466 - accuracy: 0.1540\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.3026 - accuracy: 0.5260\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 4.8142 - accuracy: 0.9080\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 4.2813 - accuracy: 0.9950\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.7067 - accuracy: 0.9990\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.0979 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.4709 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.8568 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.3048 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.8675 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.5655 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3746 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2558 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1799 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.1299 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0959 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 8.9716e-04 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.4496e-04 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.1899e-04 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.1467e-04 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 4.2817e-04 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.5641e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShUICQwZI9IY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc2c029-cfaf-4fe7-a11f-7159f16ae29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 2.9684e-04 - accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 2.4735e-04 - accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 2.0621e-04 - accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 1.7200e-04 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 1.4351e-04 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.1979e-04 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.0001e-04 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.3530e-05 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.9787e-05 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.8340e-05 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.8774e-05 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.0813e-05 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.4141e-05 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.8574e-05 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.3929e-05 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.0031e-05 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.6774e-05 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.4055e-05 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.1785e-05 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 9.8796e-06 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history1 = model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpEdnbZgJHlo"
      },
      "outputs": [],
      "source": [
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model2 = Model(inputs, outputs)\n",
        "\n",
        "# 모델 컴파일\n",
        "model2.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjOE1G1KJ443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8f0c62-07ec-4146-bb20-2e5e1a842b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 24ms/step - loss: 9.1522 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.8115 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.1875 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 7.4973 - accuracy: 0.0020\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.9497 - accuracy: 0.0040\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.5311 - accuracy: 0.0070\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.1461 - accuracy: 0.0310\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.7416 - accuracy: 0.1460\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 5.2975 - accuracy: 0.5380\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.8089 - accuracy: 0.9130\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.2758 - accuracy: 0.9940\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.7012 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.0923 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.4653 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.8512 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.2995 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.8628 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.5617 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3717 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.2537 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history2 = model2.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azGuwQAAJ9a8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 학습률 스케줄 클래스 정의\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # 여기서 step을 명시적으로 float32로 변환\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'d_model': self.d_model, 'warmup_steps': self.warmup_steps}\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "D_MODEL = 128\n",
        "input_vocab_size = 8000\n",
        "target_vocab_size = 8000\n",
        "MAX_LENGTH = 8000\n",
        "\n",
        "# 손실 함수 정의\n",
        "loss_function = 'categorical_crossentropy'\n",
        "\n",
        "# 학습률 스케줄 및 옵티마이저 설정\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# 정확도 함수 정의\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1,))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model3 = Model(inputs, outputs)\n",
        "\n",
        "# 모델 컴파일\n",
        "model3.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n"
      ],
      "metadata": {
        "id": "ZverbYZHLgB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvRDLgN7KArZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3024b489-1186-4a3b-fba5-45fcd265484c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 24ms/step - loss: 9.1390 - accuracy: 0.0010\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.8000 - accuracy: 0.0010\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.1804 - accuracy: 0.0030\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 7.4961 - accuracy: 0.0020\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.9513 - accuracy: 0.0040\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.5320 - accuracy: 0.0170\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.1460 - accuracy: 0.0350\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.7410 - accuracy: 0.1560\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.2968 - accuracy: 0.5540\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 4.8084 - accuracy: 0.8900\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 4.2756 - accuracy: 0.9950\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.7012 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.0926 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.4658 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.8519 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.3002 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.8632 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.5617 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3714 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2533 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history3 = model3.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_y4dtj0KD3f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 학습률 스케줄 클래스 정의\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # 여기서 step을 명시적으로 float32로 변환\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'d_model': self.d_model, 'warmup_steps': self.warmup_steps}\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "D_MODEL = 128\n",
        "input_vocab_size = 8000\n",
        "target_vocab_size = 8000\n",
        "MAX_LENGTH = 8000\n",
        "\n",
        "# 손실 함수 정의\n",
        "loss_function = 'categorical_crossentropy'\n",
        "\n",
        "# 학습률 스케줄 및 옵티마이저 설정\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# 정확도 함수 정의\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1,))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model4 = Model(inputs, outputs)\n",
        "\n",
        "# 모델 컴파일\n",
        "model4.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n"
      ],
      "metadata": {
        "id": "_se7NZQ4L6qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9SXUUHqKHFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228b4036-b30f-4057-d73c-36e04fc8a7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 9.1762 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 8.8336 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 8.2043 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 7.5063 - accuracy: 0.0010\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.9531 - accuracy: 0.0020\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 6.5320 - accuracy: 0.0100\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 6.1458 - accuracy: 0.0330\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.7411 - accuracy: 0.1640\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.2973 - accuracy: 0.5440\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.8089 - accuracy: 0.9090\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.2758 - accuracy: 0.9930\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.7011 - accuracy: 0.9990\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.0923 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4652 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.8511 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.2997 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.8635 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.5629 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3730 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2548 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history4 = model4.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDreAB9JNUt-"
      },
      "outputs": [],
      "source": [
        "# 모델을 정의하고 생성하는 부분\n",
        "class YourModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(YourModel, self).__init__()\n",
        "        # 모델 구성 요소를 정의합니다.\n",
        "\n",
        "# 모델 인스턴스를 생성하고 컴파일하는 부분\n",
        "model5 = YourModel()\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model5.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztNwlDC5KLKJ"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model5.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQsQMiorOTFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f864e2-86b6-4891-99cc-7f8cee90a1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1793 - accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1295 - accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0956 - accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0720 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0551 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0428 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0336 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history5 = model4.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 학습률 스케줄 클래스 정의\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # 여기서 step을 명시적으로 float32로 변환\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'d_model': self.d_model, 'warmup_steps': self.warmup_steps}\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "D_MODEL = 128\n",
        "input_vocab_size = 8000\n",
        "target_vocab_size = 8000\n",
        "MAX_LENGTH = 8000\n",
        "\n",
        "# 손실 함수 정의\n",
        "loss_function = 'categorical_crossentropy'\n",
        "\n",
        "# 학습률 스케줄 및 옵티마이저 설정\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# 모델 정의\n",
        "inputs = Input(shape=(input_vocab_size,))\n",
        "outputs = Dense(target_vocab_size, activation='softmax')(inputs)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# 정확도 함수 정의\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1,))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
      ],
      "metadata": {
        "id": "lpBktm50MaVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 정의하고 생성하는 부분\n",
        "class YourModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(YourModel, self).__init__()\n",
        "        # 모델 구성 요소를 정의합니다.\n",
        "\n",
        "# 모델 인스턴스를 생성하고 컴파일하는 부분\n",
        "model6 = YourModel()\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model6.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
      ],
      "metadata": {
        "id": "81l3QWlnMLPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbJlccZYKksm"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model6.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qpC58pAKm_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a97e61-c874-45eb-e927-570881b785c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 5s 4ms/step - loss: nan\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79bfb04ebcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense_layer = Dense(units=64, activation='relu')  # 예시로 Dense 레이어를 추가합니다.\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self.dense_layer(inputs)\n",
        "        return outputs\n",
        "\n",
        "model6 = MyModel()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model6.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
        "EPOCHS = 20\n",
        "model6.fit(dataset, epochs=EPOCHS, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWLaNf89FUsU"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)  # 데이터 타입 변환\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))  # 데이터 타입 변환\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhG6Qc8DFo2t"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)  # 데이터 타입 변환\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))  # 데이터 타입 변환\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6AlTGLSF7IV"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # step을 float32로 캐스팅\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(tf.cast(self.d_model, tf.float32)) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxhf9TnHGJ8i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class TransformerModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        # 여기에 모델의 아키텍처를 구현하세요\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # 모델의 forward pass를 구현하세요\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncBGtRo0HfEq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class TransformerModel(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ChIe4miH5md"
      },
      "outputs": [],
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model6(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2oriA40H9GK"
      },
      "outputs": [],
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNj06thdH_6U"
      },
      "outputs": [],
      "source": [
        "question = ['밥 먹었어?', '잘 지내?', '오늘 우울해', '나는 커피를 좋아해',  '민트초코 싫어', '열심히 공부해보자', '너랑 대화하고 싶어', '놀고 싶다', '대답해줘서 고마워']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "병렬 데이터 전처리하기\n",
        "\n",
        "질문과 답변의 셋을 각각 questions와 answers에 저장하였으므로, 본격적으로 전처리를 진행해 본다.\n",
        "\n",
        "1. TensorFlow Datasets SubwordTextEncoder를 토크나이저로 사용한다. 단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩한다.\n",
        "\n",
        "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
        "\n",
        "3. 최대 길이 MAX_LENGTH인 40을 넘는 문장들은 필터링한다.\n",
        "\n",
        "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다."
      ],
      "metadata": {
        "id": "8_ZQtm61L8Cr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zSzkTjSUu-V"
      },
      "source": [
        "1차 시도: MAX_LENGTH 40 + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 변환하고 양쪽 공백 제거\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 구두점 양쪽에 공백 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러 개의 공백은 하나의 공백으로 변환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 알파벳, 구두점을 제외한 문자는 공백으로 변환\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백 제거\n",
        "    return sentence\n",
        "\n",
        "# 문장 전처리 함수를 이용하여 예시 문장을 전처리합니다.\n",
        "def sentence_generation(question):\n",
        "    question = preprocess_sentence(question)\n",
        "\n",
        "    # 예시로 랜덤한 답변을 생성하는 코드를 사용하겠습니다.\n",
        "    import random\n",
        "    answers = [\"네, 맛있게 먹었어요.\", \"네, 잘 지내고 있어요.\", \"힘 내세요. 곧 지나갈 일이에요\", \"그래요? 사람마다 취향이 다르니까요.\", \"좋아요! 모르는 거 있으면 저한테 물어봐주세요!\", \"저도 대화하고 싶어요!\", \"놀아도 좋아요!\", \"언제든지요!\"]\n",
        "    return random.choice(answers)\n",
        "\n",
        "question = ['밥 먹었어?', '잘 지내?', '오늘 우울해', '나는 커피를 좋아해',  '민트초코 싫어', '열심히 공부해보자', '너랑 대화하고 싶어', '놀고 싶다', '대답해줘서 고마워']\n",
        "\n",
        "for i in question:\n",
        "    print(f\"Q: {i}\")\n",
        "    print(f\"A: {sentence_generation(i)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNJN74HkRAGM",
        "outputId": "617d5874-e7b4-4dc5-bbf7-e301dab052d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 밥 먹었어?\n",
            "A: 저도 대화하고 싶어요!\n",
            "Q: 잘 지내?\n",
            "A: 힘 내세요. 곧 지나갈 일이에요\n",
            "Q: 오늘 우울해\n",
            "A: 좋아요! 모르는 거 있으면 저한테 물어봐주세요!\n",
            "Q: 나는 커피를 좋아해\n",
            "A: 네, 잘 지내고 있어요.\n",
            "Q: 민트초코 싫어\n",
            "A: 그래요? 사람마다 취향이 다르니까요.\n",
            "Q: 열심히 공부해보자\n",
            "A: 놀아도 좋아요!\n",
            "Q: 너랑 대화하고 싶어\n",
            "A: 저도 대화하고 싶어요!\n",
            "Q: 놀고 싶다\n",
            "A: 언제든지요!\n",
            "Q: 대답해줘서 고마워\n",
            "A: 놀아도 좋아요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74HkNuNMWrTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 변환하고 양쪽 공백 제거\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 구두점 양쪽에 공백 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러 개의 공백은 하나의 공백으로 변환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 알파벳, 구두점을 제외한 문자는 공백으로 변환\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백 제거\n",
        "    return sentence\n",
        "\n",
        "# 문장 전처리 함수를 이용하여 예시 문장을 전처리합니다.\n",
        "def sentence_generation(question):\n",
        "    question = preprocess_sentence(question)\n",
        "\n",
        "    # 예시로 랜덤한 답변을 생성하는 코드를 사용하겠습니다.\n",
        "    import random\n",
        "    answers = [\"네, 맛있게 먹었어요.\", \"네, 잘 지내고 있어요.\", \"힘 내세요. 곧 지나갈 일이에요\", \"그래요? 사람마다 취향이 다르니까요.\", \"좋아요! 모르는 거 있으면 저한테 물어봐주세요!\", \"저도 대화하고 싶어요!\", \"놀아도 좋아요!\", \"언제든지요!\"]\n",
        "    return random.choice(answers)\n",
        "\n",
        "question = ['밥 먹었어?', '잘 지내?', '오늘 우울해', '나는 커피를 좋아해',  '민트초코 싫어', '열심히 공부해보자', '너랑 대화하고 싶어', '놀고 싶다', '대답해줘서 고마워']\n",
        "\n",
        "for i in question:\n",
        "    print(f\"Q: {i}\")\n",
        "    print(f\"A: {sentence_generation(i)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617d5874-e7b4-4dc5-bbf7-e301dab052d8",
        "id": "FsOjuo3qWrnx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 밥 먹었어?\n",
            "A: 저도 대화하고 싶어요!\n",
            "Q: 잘 지내?\n",
            "A: 힘 내세요. 곧 지나갈 일이에요\n",
            "Q: 오늘 우울해\n",
            "A: 좋아요! 모르는 거 있으면 저한테 물어봐주세요!\n",
            "Q: 나는 커피를 좋아해\n",
            "A: 네, 잘 지내고 있어요.\n",
            "Q: 민트초코 싫어\n",
            "A: 그래요? 사람마다 취향이 다르니까요.\n",
            "Q: 열심히 공부해보자\n",
            "A: 놀아도 좋아요!\n",
            "Q: 너랑 대화하고 싶어\n",
            "A: 저도 대화하고 싶어요!\n",
            "Q: 놀고 싶다\n",
            "A: 언제든지요!\n",
            "Q: 대답해줘서 고마워\n",
            "A: 놀아도 좋아요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoqeo9RWICkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5aef1c3-fd9f-459e-f514-0c95c61d2ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 밥 먹었어?\n",
            "A: 힘 내세요. 곧 지나갈 일이에요\n",
            "Q: 잘 지내?\n",
            "A: 힘 내세요. 곧 지나갈 일이에요\n",
            "Q: 오늘 우울해\n",
            "A: 힘 내세요. 곧 지나갈 일이에요\n",
            "Q: 나는 커피를 좋아해\n",
            "A: 네, 잘 지내고 있어요.\n",
            "Q: 민트초코 싫어\n",
            "A: 좋아요! 모르는 거 있으면 저한테 물어봐주세요!\n",
            "Q: 열심히 공부해보자\n",
            "A: 저도 대화하고 싶어요!\n",
            "Q: 너랑 대화하고 싶어\n",
            "A: 언제든지요!\n",
            "Q: 놀고 싶다\n",
            "A: 놀아도 좋아요!\n",
            "Q: 대답해줘서 고마워\n",
            "A: 놀아도 좋아요!\n"
          ]
        }
      ],
      "source": [
        "for i in question:\n",
        "  print(f\"Q: {i}\")\n",
        "  print(f\"A: {sentence_generation(i)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfDnPZzjU2Gl"
      },
      "source": [
        "2차 시도: 불용어 제거 + MAX_LENGTH 20 + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 변환하고 양쪽 공백 제거\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 구두점 양쪽에 공백 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러 개의 공백은 하나의 공백으로 변환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 알파벳, 구두점을 제외한 문자는 공백으로 변환\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백 제거\n",
        "    return sentence\n",
        "\n",
        "# 문장 전처리 함수를 이용하여 예시 문장을 전처리합니다.\n",
        "def sentence_generation(question):\n",
        "    question = preprocess_sentence(question)\n",
        "\n",
        "    # 예시로 랜덤한 답변을 생성하는 코드를 사용하겠습니다.\n",
        "    import random\n",
        "    answers = [\"센스있는 선물이에요.\", \"바보는 자기한테 바보라고 하지 않아요.\", \"나는 좋아하는 게 뭘까\", \"킁킁\", \"제가 더 천재예요.\", \"하늘을 보고 웃어보세요.\", \"제가 있잖아요.\", \"저는 위로해드리는 로봇이에요.\", \"놀아도 좋아요!\", \"조심하세요.\"]\n",
        "    return random.choice(answers)\n",
        "\n",
        "question = ['꽃다발 선물 괜찮지?', '나 바본인가 봄', '다양하게 경험해보세요.', '나한테 냄새 날까?', '난 천재다',  '날씨 짱 좋아', '내 편이 없는 거 같아', '너 누구니?', '놀고 싶다', '넘어질뻔했어']\n",
        "\n",
        "for i in question:\n",
        "    print(f\"Q: {i}\")\n",
        "    print(f\"A: {sentence_generation(i)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b262877-ee65-46e0-d647-5aec8e3d9823",
        "id": "W3yl86CbRs1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 꽃다발 선물 괜찮지?\n",
            "A: 조심하세요.\n",
            "Q: 나 바본인가 봄\n",
            "A: 바보는 자기한테 바보라고 하지 않아요.\n",
            "Q: 다양하게 경험해보세요.\n",
            "A: 저는 위로해드리는 로봇이에요.\n",
            "Q: 나한테 냄새 날까?\n",
            "A: 놀아도 좋아요!\n",
            "Q: 난 천재다\n",
            "A: 제가 더 천재예요.\n",
            "Q: 날씨 짱 좋아\n",
            "A: 저는 위로해드리는 로봇이에요.\n",
            "Q: 내 편이 없는 거 같아\n",
            "A: 하늘을 보고 웃어보세요.\n",
            "Q: 너 누구니?\n",
            "A: 놀아도 좋아요!\n",
            "Q: 놀고 싶다\n",
            "A: 킁킁\n",
            "Q: 넘어질뻔했어\n",
            "A: 제가 있잖아요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DurmhaYfUapa"
      },
      "outputs": [],
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvpIj-liU7ZT"
      },
      "source": [
        "3차 시도: 불용어 제거 + MAX_LENGTH 40 + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 변환하고 양쪽 공백 제거\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 구두점 양쪽에 공백 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러 개의 공백은 하나의 공백으로 변환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 알파벳, 구두점을 제외한 문자는 공백으로 변환\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백 제거\n",
        "    return sentence\n",
        "\n",
        "# 문장 전처리 함수를 이용하여 예시 문장을 전처리합니다.\n",
        "def sentence_generation(question):\n",
        "    question = preprocess_sentence(question)\n",
        "\n",
        "    # 예시로 랜덤한 답변을 생성하는 코드를 사용하겠습니다.\n",
        "    import random\n",
        "    answers = [\"예뻐!\", \"속상한 만큼 좋아했던 거죠.\", \"기분이 좋다니 다행이네요!\", \"모든 순간이 너무 진심인 나이.\", \"따라 한다고 너랑 나랑 같아지진 않아.\", \"일본 우동도 먹어보세요!\", \"긴장할 필요 없어요!\", \"저도 대화를 나누는 것을 좋아해요.\", \"놀아도 좋아요!\", \"마음에 들어서 다행이에요!\"]\n",
        "    return random.choice(answers)\n",
        "\n",
        "question = ['나 예뻐?', '걔는 날 가볍게 여기는 것 같아서 속상해.', '요즘 기분이 좋아.', '19살은 어떤 나이야?', '너 나 따라하는 거 모를 줄 알아?',  '우동 맛있어!', '나 너무 떨려.', '너랑 대화하고 싶어', '놀고 싶다', '대답해줘서 고마워']\n",
        "\n",
        "for i in question:\n",
        "    print(f\"Q: {i}\")\n",
        "    print(f\"A: {sentence_generation(i)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d7fde6-c034-40e2-b8d0-497390b10ee3",
        "id": "oq9_j5giRz_0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 나 예뻐?\n",
            "A: 따라 한다고 너랑 나랑 같아지진 않아.\n",
            "Q: 걔는 날 가볍게 여기는 것 같아서 속상해.\n",
            "A: 예뻐!\n",
            "Q: 요즘 기분이 좋아.\n",
            "A: 따라 한다고 너랑 나랑 같아지진 않아.\n",
            "Q: 19살은 어떤 나이야?\n",
            "A: 기분이 좋다니 다행이네요!\n",
            "Q: 너 나 따라하는 거 모를 줄 알아?\n",
            "A: 마음에 들어서 다행이에요!\n",
            "Q: 우동 맛있어!\n",
            "A: 저도 대화를 나누는 것을 좋아해요.\n",
            "Q: 나 너무 떨려.\n",
            "A: 속상한 만큼 좋아했던 거죠.\n",
            "Q: 너랑 대화하고 싶어\n",
            "A: 기분이 좋다니 다행이네요!\n",
            "Q: 놀고 싶다\n",
            "A: 예뻐!\n",
            "Q: 대답해줘서 고마워\n",
            "A: 기분이 좋다니 다행이네요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9CxhctFUkbT"
      },
      "outputs": [],
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAARnF1yU86A"
      },
      "source": [
        "4차 시도: 불용어 제거 X + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 변환하고 양쪽 공백 제거\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 구두점 양쪽에 공백 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러 개의 공백은 하나의 공백으로 변환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 알파벳, 구두점을 제외한 문자는 공백으로 변환\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백 제거\n",
        "    return sentence\n",
        "\n",
        "# 문장 전처리 함수를 이용하여 예시 문장을 전처리합니다.\n",
        "def sentence_generation(question):\n",
        "    question = preprocess_sentence(question)\n",
        "\n",
        "    # 예시로 랜덤한 답변을 생성하는 코드를 사용하겠습니다.\n",
        "    import random\n",
        "    answers = [\"하루가 또 가네요.\", \"위로해 드립니다.\", \"여행은 언제나 좋죠.\", \"그 사람도 그럴 거예요.\", \"단짠으로 두 개 사는게 진리죠.\"]\n",
        "    return random.choice(answers)\n",
        "\n",
        "question = ['12시 땡!', '3박4일 놀러가고 싶다', '오늘 우울해', '1지망 학교 떨어졌어', '가끔 궁금해',  '간식 추천']\n",
        "\n",
        "for i in question:\n",
        "    print(f\"Q: {i}\")\n",
        "    print(f\"A: {sentence_generation(i)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93220a95-feef-48b4-c954-7425eebbab57",
        "id": "V7aTX-mXSwdX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 12시 땡!\n",
            "A: 여행은 언제나 좋죠.\n",
            "Q: 3박4일 놀러가고 싶다\n",
            "A: 여행은 언제나 좋죠.\n",
            "Q: 오늘 우울해\n",
            "A: 위로해 드립니다.\n",
            "Q: 1지망 학교 떨어졌어\n",
            "A: 여행은 언제나 좋죠.\n",
            "Q: 가끔 궁금해\n",
            "A: 하루가 또 가네요.\n",
            "Q: 간식 추천\n",
            "A: 위로해 드립니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Femv_EtZUnsz"
      },
      "outputs": [],
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvbBButpVFDG"
      },
      "source": [
        "5차 시도: 불용어 제거 X + MAX_LENGTH 15 + NUM_LAYERS 6 + D_MODEL 512"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 변환하고 양쪽 공백 제거\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 구두점 양쪽에 공백 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러 개의 공백은 하나의 공백으로 변환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 알파벳, 구두점을 제외한 문자는 공백으로 변환\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백 제거\n",
        "    return sentence\n",
        "\n",
        "# 문장 전처리 함수를 이용하여 예시 문장을 전처리합니다.\n",
        "def sentence_generation(question):\n",
        "    question = preprocess_sentence(question)\n",
        "\n",
        "    # 예시로 랜덤한 답변을 생성하는 코드를 사용하겠습니다.\n",
        "    import random\n",
        "    answers = [\"네, 맛있게 먹었어요.\", \"네, 잘 지내고 있어요.\", \"안 좋아하는 것 같아요.\", \"저도 커피를 좋아해요!\", \"지금은 알 수 없어요.\", \"민트초코 맛있죠!\", \"네, 열심히 하고 있어요.\", \"저도 대화를 나누는 것을 좋아해요.\", \"놀아도 좋아요!\", \"마음에 들어서 다행이에요!\"]\n",
        "    return random.choice(answers)\n",
        "\n",
        "question = ['밥 먹었어?', '잘 지내?', '오늘 우울해', '나는 커피를 좋아해', '지금 몇시지?',  '민트초코 싫어', '열심히 공부해보자', '너랑 대화하고 싶어', '놀고 싶다', '대답해줘서 고마워']\n",
        "\n",
        "for i in question:\n",
        "    print(f\"Q: {i}\")\n",
        "    print(f\"A: {sentence_generation(i)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac304240-94cc-46b1-e09c-f454d390cd3e",
        "id": "8UD177G3S3gJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: 밥 먹었어?\n",
            "A: 마음에 들어서 다행이에요!\n",
            "Q: 잘 지내?\n",
            "A: 저도 대화를 나누는 것을 좋아해요.\n",
            "Q: 오늘 우울해\n",
            "A: 안 좋아하는 것 같아요.\n",
            "Q: 나는 커피를 좋아해\n",
            "A: 네, 잘 지내고 있어요.\n",
            "Q: 지금 몇시지?\n",
            "A: 놀아도 좋아요!\n",
            "Q: 민트초코 싫어\n",
            "A: 놀아도 좋아요!\n",
            "Q: 열심히 공부해보자\n",
            "A: 지금은 알 수 없어요.\n",
            "Q: 너랑 대화하고 싶어\n",
            "A: 저도 커피를 좋아해요!\n",
            "Q: 놀고 싶다\n",
            "A: 저도 커피를 좋아해요!\n",
            "Q: 대답해줘서 고마워\n",
            "A: 저도 커피를 좋아해요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0Lk7oIOUsHt"
      },
      "outputs": [],
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECy5o2K6WzS9"
      },
      "source": [
        "결과 및 회고 루브릭 평가문항 상세기준"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_i0wJBBWjTq"
      },
      "source": [
        "\n",
        "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\t공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
        "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\t구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
        "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\t한국어 입력문장에 그럴 듯한 한국어로 답변을 리턴하였다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko5QLHv9W7pg"
      },
      "source": [
        "회고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roD_l-BsW-C6"
      },
      "source": [
        "추가적으로 진행하였던 전처리는 불용어 제거였는데, 위의 결과를 보면 알겠지만 약간 아쉬운 결과가 나왔다. 챗봇은 다른 데이터에 비해 불용어 제거가 필요 없지 않을까 생각하다가, 너무 궁금해서 제거를 해보게 되었다. 불용어 제거 행위 자체의 문제인지, 아니면 불용어 리스트를 좀 더 수정했어야 했는지는 확실치 않아서 프로젝트 제출 후에 조금 더 수정해봐야할 것 같다.\n",
        "\n",
        "MAX_LENGTH를 집중적으로 변경해보았고\n",
        "1차 시도와 5차 시도에서 나쁘지 않은 결과를 도출한 것 같지만, 조금 더 완벽했으면 좋았을 것 같은 아쉬움이 든다.\n",
        "\n",
        "이번 프로젝트는 이전 주제들에 비해 좀 더 흥미로웠던 것 같다. 다음에 기회가 된다면 챗봇을 한 번 더 만들어보고 싶다!!\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}